{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urban Definition\n",
    "--------------\n",
    "\n",
    "Select the census urban areas definitions with a spatial join of the Metro stats areas\n",
    "\n",
    "Them:\n",
    "  - Used Metro Statistical Area of 50 largest cities\n",
    "  - Buffered by 50km, removed +/- 50m elevation area, removed neighboring urban areas\n",
    "  \n",
    "Us:\n",
    "  - Use metro stats area of urban extents\n",
    "  - Buffer by 50k, remove neighboring extents, remove elevation areas +/- 50m\n",
    "\n",
    "Timeframe and data \n",
    "----------------\n",
    "2010\n",
    "Prism, Dayment, Station Data, Modis\n",
    "\n",
    "Function\n",
    "----------------\n",
    "(Urban & spatial average * tMin) - (Urban & spatial average * tMin)\n",
    "\n",
    "\n",
    "Stats\n",
    "-----------------\n",
    " - Avg of daily values for the summer months (June, July, August) in 2010\n",
    " ~~- Average across all of 2010~~\n",
    " ~~- 2006-2010 average~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the closest station to downtown\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from shapely import wkb\n",
    "import os\n",
    "import requests\n",
    "POSTGRESURI = 'postgresql://urbis:urbis@ontoserv:5434/urbisdata01'\n",
    "engine = create_engine(POSTGRESURI)\n",
    "\n",
    "import pickle\n",
    "sampleplaces = {}\n",
    "for fname in os.listdir('Dabbage/pickles'):\n",
    "    with open(os.path.join('Dabbage', 'pickles', fname), 'rb') as fin:\n",
    "        tempobj = pickle.load(fin)\n",
    "        sampleplaces[tempobj['placeid']] = tempobj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely import wkb\n",
    "from pyspatial.vector import from_series\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import json\n",
    "import numpy as np\n",
    "from pyspatial.raster import read_catalog, read_raster\n",
    "import traceback\n",
    "from dateutil.parser import parse as dateparser\n",
    "#set up the years that we will use\n",
    "yearset = {}\n",
    "for year in range(2010,2011):\n",
    "    starttime = dateparser(\"{0}-06-01\".format(year))\n",
    "    endtime = dateparser(\"{0}-08-31\".format(year))\n",
    "    numberdays = endtime - starttime\n",
    "    yearset[year] = pd.date_range(starttime, periods=numberdays.days+1, freq='D')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#set up the vector layer df that we will use\n",
    "geomsetkeys = [x['placeid'] for x in sampleplaces.values() if x['censusurb'].get('processbuffer')]\n",
    "urbanvl = from_series(pd.Series([x['censusurb']['geom'] for x in sampleplaces.values() if x['censusurb'].get('processbuffer')]))\n",
    "\n",
    "buffervl = from_series(pd.Series([x['censusurb']['processbuffer'] for x in sampleplaces.values() if x['censusurb'].get('processbuffer')]))\n",
    "\n",
    "\n",
    "for s in sampleplaces.values():\n",
    "    s['prismresults'] = {\n",
    "        'buffertmax' : {},\n",
    "        'buffertmin' : {},\n",
    "        'buffertavg' : {},\n",
    "        'urbantmax': {},\n",
    "        'urbantmin': {},\n",
    "        'urbantavg': {}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "f = FloatProgress(min=0, max=len(yearset.values()[0]))\n",
    "display(f)\n",
    "\n",
    "\n",
    "PRISMDIR = '/Volumes/UrbisBackup/rasterstorage/prism'\n",
    "\n",
    "for year, daterng in yearset.iteritems():\n",
    "    for daymetdate in daterng:\n",
    "        f.value += 1\n",
    "#         print \"doing {0}\".format(daymetdate)\n",
    "        daymettimetuple = daymetdate.timetuple()\n",
    "        day = daymetdate.day \n",
    "        month = daymetdate.month\n",
    "        year = daymettimetuple.tm_year\n",
    "        yday = daymettimetuple.tm_yday\n",
    "\n",
    "        tminprismfilename = \"(PRISM_{measure}_stable_4kmD1_{year}{month}{day}_bil).tif\"\\\n",
    "                                         .format(measure = 'tmin',\n",
    "                                                year = year,\n",
    "                                                month = str(month).zfill(2),\n",
    "                                                day = str(day).zfill(2))\n",
    "            \n",
    "        tmaxprismfilename = \"(PRISM_{measure}_stable_4kmD1_{year}{month}{day}_bil).tif\"\\\n",
    "                                 .format(measure = 'tmax',\n",
    "                                        year = year,\n",
    "                                        month = str(month).zfill(2),\n",
    "                                        day = str(day).zfill(2))\n",
    "\n",
    "\n",
    "        try:\n",
    "            tminraster = read_raster(op.join(PRISMDIR, tminprismfilename))\n",
    "            tmaxraster = read_raster(op.join(PRISMDIR, tmaxprismfilename))\n",
    "        except Exception,e:\n",
    "            traceback.print_exc()\n",
    "            print \"{0} Does not exist in the file system\".format(daymetfilename)\n",
    "            for s in sampleplaces.values():\n",
    "                s['prismresults']['buffertmin'][daymetdate] = np.NaN\n",
    "                s['prismresults']['buffertmax'][daymetdate] = np.NaN\n",
    "                s['prismresults']['buffertavg'][daymetdate] = np.NaN\n",
    "                s['prismresults']['urbantmin'][daymetdate] = np.NaN\n",
    "                s['prismresults']['urbantmax'][daymetdate] = np.NaN\n",
    "                s['prismresults']['urbantavg'][daymetdate] = np.NaN\n",
    "            continue\n",
    "\n",
    "        resultset = {\n",
    "            ('urban', 'tmin',): tminraster.query(urbanvl),\n",
    "            ('urban', 'tmax',): tmaxraster.query(urbanvl),\n",
    "            ('buffer', 'tmin',): tminraster.query(buffervl),\n",
    "            ('buffer', 'tmax',): tmaxraster.query(buffervl)\n",
    "        }\n",
    "\n",
    "        for resultkey, result in resultset.iteritems():\n",
    "            for r,skey in zip(result, geomsetkeys):\n",
    "                s = sampleplaces[skey]\n",
    "                try:\n",
    "                    indexc = np.argwhere(r.values > -150)\n",
    "                    newv =  np.take(r.values, indexc)\n",
    "                    neww =  np.take(r.weights, indexc)\n",
    "                    s['prismresults'][\"\".join(resultkey)][daymetdate] = float((newv * neww).sum() / neww.sum())\n",
    "                except Exception,e:\n",
    "#                     print e\n",
    "                    s['prismresults'][\"\".join(resultkey)][daymetdate] = np.NaN\n",
    "        for skey in geomsetkeys:\n",
    "            s = sampleplaces[skey]\n",
    "            try:\n",
    "                s['prismresults']['buffertavg'][daymetdate] = np.mean([s['prismresults']['buffertmin'][daymetdate], s['prismresults']['buffertmax'][daymetdate]])   \n",
    "                s['prismresults']['urbantavg'][daymetdate] = np.mean([s['prismresults']['urbantmin'][daymetdate], s['prismresults']['urbantmax'][daymetdate]])   \n",
    "            except Exception,e:\n",
    "#                 print e\n",
    "                s['prismresults']['buffertavg'][daymetdate] = np.NaN\n",
    "                s['prismresults']['urbantavg'][daymetdate] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print sampleplaces.values()[0]\n",
    "for k,s in sampleplaces.iteritems():\n",
    "#     if s.get('usgsplacegeom'):\n",
    "#         del s['usgsplacegeom']\n",
    "#     if s.get('usgsplacegeomwgs84'):\n",
    "#         del s['usgsplacegeomwgs84']\n",
    "#     if s.get('earthenv'):\n",
    "#         del s['earthenv']\n",
    "    s['usgsplacegeomstr'] = str(s['usgsplacegeomstr'])\n",
    "    s['usgsplacegeomwgs84str'] = str(s['usgsplacegeomwgs84str'])\n",
    "    \n",
    "import pickle\n",
    "with open('dabbage/dabbageprism.pickle', 'wb') as fout:\n",
    "    pickle.dump(sampleplaces, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Antonio Timestamp('2010-06-01 00:00:00', offset='D')\n",
      "Omaha Timestamp('2010-06-01 00:00:00', offset='D')\n",
      "Lincoln Timestamp('2010-06-01 00:00:00', offset='D')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "outputdict = []\n",
    "\n",
    "for s in sampleplaces.values():\n",
    "    try:\n",
    "        dictholder = []\n",
    "        for year, daterng in yearset.iteritems():\n",
    "            for daymetdate in daterng:\n",
    "                tempholder = []\n",
    "                for rmeasure in ['urbantmin', 'urbantmax', 'urbantavg', 'buffertmin', 'buffertmax', 'buffertavg']:\n",
    "                    tempholder.append(s['prismresults'][rmeasure][daymetdate])\n",
    "                dictholder.append([year, daymetdate, rmeasure] + tempholder)\n",
    "\n",
    "        df = pd.DataFrame(dictholder, columns=['year', 'date', 'rmeasure', 'urbantmin', \\\n",
    "                                               'urbantmax', 'urbantavg', 'buffertmin', 'buffertmax', 'buffertavg'])\n",
    "        # group by year with mean\n",
    "        urbanresult = pd.DataFrame(df.groupby(['year'])['urbantmin', 'urbantmax', \\\n",
    "                                                        'urbantavg', 'buffertmin', \\\n",
    "                                                        'buffertmax', 'buffertavg'].mean()).reset_index()\n",
    "        finalresult = urbanresult.mean().reset_index()\n",
    "\n",
    "        outputdict.append({\n",
    "                'placeid': s['placeid'],\n",
    "                'placename': s['usgsplacename'],\n",
    "                'uhitmin':     float(finalresult.loc[finalresult['index'] == 'urbantmin'][0]) \\\n",
    "                                - float(finalresult.loc[finalresult['index'] == 'buffertmin'][0]),\n",
    "                'uhitavg': float(finalresult.loc[finalresult['index'] == 'urbantavg'][0]) \\\n",
    "                                - float(finalresult.loc[finalresult['index'] == 'buffertavg'][0]),\n",
    "                'uhitmax': float(finalresult.loc[finalresult['index'] == 'urbantmax'][0]) \\\n",
    "                                - float(finalresult.loc[finalresult['index'] == 'buffertmax'][0])\n",
    "            })\n",
    "    except Exception,e:\n",
    "        print \"ERROR\",s['usgsplacename'], e\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('Dabbage/dabbage_prism.csv', 'w') as fin:\n",
    "    writer = csv.DictWriter(fin, fieldnames=['placeid', 'placename', 'uhitmin', 'uhitmax', 'uhitavg'])\n",
    "    writer.writeheader()\n",
    "    for row in outputdict:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
