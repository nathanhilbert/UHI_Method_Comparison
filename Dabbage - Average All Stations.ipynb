{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the closest station to downtown\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from shapely import wkb\n",
    "import os\n",
    "import requests\n",
    "POSTGRESURI = 'postgresql://urbis:urbis@ontoserv:5434/urbisdata01'\n",
    "engine = create_engine(POSTGRESURI)\n",
    "\n",
    "import pickle\n",
    "sampleplaces = {}\n",
    "for fname in os.listdir('Dabbage/pickles'):\n",
    "    with open(os.path.join('Dabbage', 'pickles', fname), 'rb') as fin:\n",
    "        tempobj = pickle.load(fin)\n",
    "        sampleplaces[tempobj['placeid']] = tempobj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'usgsplacename': u'Fort Wayne', 'earthenv': {'wgs84': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7db50>, 'ruralgeomwgs84': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7db90>, 'geom': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7d910>, 'ruralgeom': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7dc10>}, u'statefips': u'18', u'usgsplacegeomstr': '\\x01\\x04\\x00\\x00 \\x11\\x0f\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00x$\\t\\xaa2\\x13b\\xc1\\x18\\x06w7\\xb21SA', u'placeid': 7890, 'usgsplacegeom': <shapely.geometry.multipoint.MultiPoint object at 0x118d7dc50>, u'usgspopulation': 253691.0, u'gnisid': 434689.0, u'usgsplacegeomwgs84str': '\\x01\\x04\\x00\\x00 \\xe6\\x10\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00kQ\\xc1<?HU\\xc0\\xae\\x1a\\x97\\xa2\\xb7\\x90D@', 'usgsplacegeomwgs84': <shapely.geometry.multipoint.MultiPoint object at 0x118d7dd10>, u'countryfips': u'003', 'censusurb': {'processbuffer': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7dd50>, 'ruralgeomwgs84': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7dc90>, 'wgs84': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7dcd0>, 'ruralgeom': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7dd90>, 'geom': <shapely.geometry.multipolygon.MultiPolygon object at 0x118d7ddd0>}}\n"
     ]
    }
   ],
   "source": [
    "print sampleplaces.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = size / 200     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping San Antonio\n",
      "skipping Omaha\n",
      "skipping Lincoln\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "\n",
    "#project to wgs for availabilty\n",
    "projector = partial(\n",
    "    pyproj.transform,\n",
    "    pyproj.Proj(init='epsg:3857'),\n",
    "    pyproj.Proj(init='epsg:4326'))\n",
    "\n",
    "for s in log_progress(sampleplaces.values(), every=1):\n",
    "    if not s['censusurb'].get('processbuffer', False):\n",
    "        print \"skipping\", s['usgsplacename']\n",
    "        continue\n",
    "    else:\n",
    "        s['censusurb']['processbufferwgs'] = transform(projector, s['censusurb']['processbuffer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping San Antonio with no processbufferwgs\n",
      "skipping Omaha with no processbufferwgs\n",
      "skipping Lincoln with no processbufferwgs\n"
     ]
    }
   ],
   "source": [
    "# get urban and rural stations\n",
    "from shapely.geometry import Point\n",
    "import acis\n",
    "import json\n",
    "\n",
    "for s in log_progress(sampleplaces.values(), every=1):\n",
    "    if s.get('allstations', False):\n",
    "        continue\n",
    "    if not s['censusurb'].get('processbufferwgs', False):\n",
    "        print \"skipping\", s[u'usgsplacename'], \"with no processbufferwgs\"\n",
    "        continue\n",
    "\n",
    "    bbox = \",\".join([str(x) for x in s['censusurb']['processbufferwgs'].bounds])\n",
    "\n",
    "    closeststation = None\n",
    "    res = requests.get(\"http://data.rcc-acis.org/StnMeta?bbox={0}&sdate=2010-06-01&edate=2010-09-01&output=json\".format(bbox))\n",
    "    stationresults = json.loads(res.text)\n",
    "    urbanstations = []\n",
    "    ruralstations = []\n",
    "    for station in stationresults['meta']:\n",
    "        if len(station['sids']) == 0:\n",
    "            continue\n",
    "        stationpoint = Point(station['ll'])\n",
    "        if stationpoint.within(s['censusurb']['wgs84']):\n",
    "            urbanstations.append(station)\n",
    "        elif stationpoint.within(s['censusurb']['processbufferwgs']):\n",
    "            ruralstations.append(station)\n",
    "    s['allstations'] = {\n",
    "        'urbanstations': urbanstations,\n",
    "        'ruralstations': ruralstations\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:32: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping San Antonio with no processbufferwgs\n",
      "skipping Omaha with no processbufferwgs\n",
      "timed out\n",
      "skipping Lincoln with no processbufferwgs\n"
     ]
    }
   ],
   "source": [
    "#get stations data\n",
    "import pandas as pd\n",
    "import acis\n",
    "import numpy as np\n",
    "for k,s in log_progress(sampleplaces.iteritems(), every=1):\n",
    "    if not s['censusurb'].get('processbufferwgs', False):\n",
    "        print \"skipping\", s[u'usgsplacename'], \"with no processbufferwgs\"\n",
    "        continue\n",
    "    toprocess = ('urbanstations', 'ruralstations',)\n",
    "    for processkey in toprocess:\n",
    "        success = 0\n",
    "        for station in s['allstations'][processkey]:\n",
    "            try:\n",
    "                request = acis.StnDataRequest()  # change Request type\n",
    "                request.location(sid=station['sids'][0])  # change keyword and SID list\n",
    "                request.dates(\"2010-06-01\", \"2010-09-01\")  # sdate and edate\n",
    "                request.add_element(\"maxt\")\n",
    "                request.add_element(\"avgt\")\n",
    "                request.add_element(\"mint\")\n",
    "                request.metadata(\"name\")\n",
    "                result = acis.StnDataResult(request.submit())  # change Result type\n",
    "                \n",
    "                df = pd.DataFrame([x for x in result], columns=['uid', 'date', 'tmax', 'tavg','tmin'])\n",
    "                df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "                df = df.set_index(pd.DatetimeIndex(df['date']))\n",
    "                tempresults = []\n",
    "                for year in range(2010, 2011):\n",
    "                    subset = df[(df['date'] > '{0}-5-31'.format(year)) & (df['date'] <= '{0}-8-31'.format(year))]\n",
    "                    fails = 0\n",
    "                    for measures in ('tmin', 'tmax', 'tavg',):\n",
    "                        try:\n",
    "                            tempresults.append([measures, str(year), \\\n",
    "                                                subset[measures].astype(str).convert_objects(convert_numeric=True).mean()])\n",
    "                        except Exception,e:\n",
    "                            tempresults.append([measures, str(year), np.NaN])\n",
    "\n",
    "                station['results'] = tempresults\n",
    "                if processkey == 'urbanstations':\n",
    "                    if s['allstations'].get('urbanuse', False):\n",
    "                        s['allstations']['urbanuse'].append(station)\n",
    "                    else:\n",
    "                        s['allstations']['urbanuse'] = [station]\n",
    "                else:\n",
    "                    if s['allstations'].get('ruraluse', False):\n",
    "                        s['allstations']['ruraluse'].append(station)\n",
    "                    else:\n",
    "                        s['allstations']['ruraluse'] = [station]\n",
    "            except Exception, e:\n",
    "                if str(e).find(\"no data available\") == -1:\n",
    "                    print e\n",
    "                continue                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print sampleplaces.values()[0]\n",
    "for k,s in sampleplaces.iteritems():\n",
    "#     if s.get('usgsplacegeom'):\n",
    "#         del s['usgsplacegeom']\n",
    "#     if s.get('usgsplacegeomwgs84'):\n",
    "#         del s['usgsplacegeomwgs84']\n",
    "#     if s.get('earthenv'):\n",
    "#         del s['earthenv']\n",
    "    s['usgsplacegeomstr'] = str(s['usgsplacegeomstr'])\n",
    "    s['usgsplacegeomwgs84str'] = str(s['usgsplacegeomwgs84str'])\n",
    "    \n",
    "import pickle\n",
    "with open('Dabbage/dabbage_allstations.pickle', 'wb') as fout:\n",
    "    pickle.dump(sampleplaces, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping San Antonio\n",
      "skipping Omaha\n",
      "skipping Lincoln\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "outputdict = []\n",
    "\n",
    "for s in sampleplaces.values():\n",
    "    if not s.get('allstations', False):\n",
    "        print \"skipping\", s['usgsplacename']\n",
    "        continue\n",
    "    urbanuse = s['allstations'].get('urbanuse', None)\n",
    "    if not urbanuse:\n",
    "        print \"skipping\", s['usgsplacename']\n",
    "        continue\n",
    "    urbandfs = []\n",
    "    for u in urbanuse:\n",
    "        tdf = pd.DataFrame(u['results'], columns=['measure', 'year', 'value'])\n",
    "        tdf.set_index(['measure', 'year'])\n",
    "        urbandfs.append(tdf)\n",
    "        \n",
    "    udf_concat = pd.concat(urbandfs)\n",
    "    urbanresult = pd.DataFrame(udf_concat.groupby(['measure','year'])['value'].mean()).reset_index()\n",
    "    \n",
    "    ruraluse = s['allstations'].get('ruraluse', [])\n",
    "    \n",
    "    if len(ruraluse) == 0:\n",
    "        outputdict.append({\n",
    "            'placename': s['usgsplacename'],\n",
    "            'uhitmin': \"no rural\",\n",
    "            'uhitavg': \"no rural\",\n",
    "            'uhitmax': \"no rural\"\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    ruraldfs = []\n",
    "    for r in ruraluse:\n",
    "        tdf = pd.DataFrame(r['results'], columns=['measure', 'year', 'value'])\n",
    "        tdf.set_index(['measure', 'year'])\n",
    "        ruraldfs.append(tdf)\n",
    "    df_concat = pd.concat(ruraldfs)\n",
    "    ruralresult = pd.DataFrame(df_concat.groupby(['measure','year'])['value'].mean()).reset_index()\n",
    "\n",
    "    \n",
    "    mergeddf =  urbanresult.merge(ruralresult,on=['measure','year'],how='left')\n",
    "#     print mergeddf[['value_x', 'value_y']].sub(axis=1)\n",
    "    mergeddf['uhi'] = mergeddf['value_x'] - mergeddf['value_y']\n",
    "    outputdict.append({\n",
    "            'placeid': s['placeid'],\n",
    "            'placename': s['usgsplacename'],\n",
    "            'uhitmin': mergeddf[mergeddf['measure']=='tmin']['uhi'].mean(),\n",
    "            'uhitavg': mergeddf[mergeddf['measure']=='tavg']['uhi'].mean(),\n",
    "            'uhitmax': mergeddf[mergeddf['measure']=='tmax']['uhi'].mean()\n",
    "        })\n",
    "#     print mergeddf[['value_x']].sub(mergeddf['value_y'], axis=0)\n",
    "#     for year in range(2004, 2014):\n",
    "#         for measure in ['tmin', 'tmax', 'tavg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('Dabbage/allstations.csv', 'w') as fin:\n",
    "    writer = csv.DictWriter(fin, fieldnames=['placeid', 'placename', 'uhitmin', 'uhitmax', 'uhitavg'])\n",
    "    writer.writeheader()\n",
    "    for row in outputdict:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
